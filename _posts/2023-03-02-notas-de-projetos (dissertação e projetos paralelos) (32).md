---
tags:
  - projetos
  - gerais
  - interessesgerais
  - interessesdepesquisa
  - meta
  - promptgpt3
title: 131220222146
---

# 131220222146

## criado em: 21:46 2022-12-13

### Relacionado

- palavras-chave:   
- notas: 
- [[wired with a coder]]
- [[peso neural]]
- [[gpt3]]
- [[gpt3 por ele mesmo]]
---

# como o computador “aprende”?

>Backpropagation é um método usado para treinar redes neurais artificiais. É uma técnica para atualizar os pesos da rede para reduzir o erro entre a saída prevista e a saída real. *Os pesos* são atualizados com base no gradiente de erro, que é calculado usando as derivadas parciais da função de erro em relação a cada *peso*. Este processo é chamado de backpropagation porque o gradiente de erro é "propagado" para trás através da rede, começando pela camada de saída e trabalhando para trás através das camadas ocultas até chegar à camada de entrada. Os pesos são então atualizados para reduzir o erro na saída prevista. Desta forma, o backpropagation permite que a rede aprenda com os dados de treinamento e melhore seu desempenho em entradas futuras.
