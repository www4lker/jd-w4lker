---
tags:
  - projetos
  - gerais
  - interessesgerais
  - interessesdepesquisa
  - meta
  - promptgpt3
  - wiredetal
title: 161220221009
---

# 161220221009

## criado em: 10:09 2022-12-16

### Relacionado

palavras-chave:

- notas: [[chatgpt]]
- [[gpt3]]
---

# ChatGPT’s Most Charming Trick Is Also Its Biggest Flaw

## The articulate new chatbot has won over the internet and shown how engaging conversational AI can be—even when it makes stuff up.

O chatbot do OpenAI, ChatGPT, é um serviço gratuito que ganhou popularidade nas últimas semanas por sua capacidade de gerar pequenos ensaios e responder perguntas complexas sobre uma variedade de tópicos. Ele é baseado em uma versão do modelo AI GPT-3 que gera texto baseado em padrões que aprendeu com grandes quantidades de dados coletados da web. A última variante do modelo, chamada GPT-3.5, tem uma nova interface que lhe permite responder mais facilmente a perguntas naturalmente formuladas. OpenAI utilizou respostas escritas por humanos como dados de treinamento e usou o aprendizado de reforço para melhorar as respostas do modelo a perguntas de exemplo. Alguns especialistas elogiaram a interface naturalista do chatbot e seu potencial para tornar as ferramentas da linguagem AI mais acessíveis, mas outros apontaram que ela ainda é propensa a inventar fatos e regurgitar declarações tendenciosas ou de ódio.

>Alguns especialistas elogiaram a interface naturalista do chatbot e seu potencial para tornar as ferramentas da linguagem AI mais acessíveis, mas outros apontaram que ela ainda é propensa a inventar fatos e regurgitar declarações tendenciosas ou de ódio.

---

# Wired’s plaintext on chatgpt

>A professora Sandra Wachter do Oxford Internet Institute fala sobre o potencial do ChatGPT, um chatbot gratuito que usa uma variante do modelo GPT-3 do OpenAI, para ser usado para enganar os estudantes. Wachter sugere o uso de marcas d'água e ferramentas tecnológicas para detectar a produção criada artificialmente como soluções potenciais para esta questão, além de fomentar a pesquisa de ferramentas independentes para detectar a produção de IA e ser mais criativa na avaliação dos estudantes. Wachter também discute a importância de contrafactuais, ou ser capaz de mudar os dados de entrada para ver como isso afeta as decisões sobre IA, na compreensão e prevenção de danos causados pela IA. Ela destaca o potencial para bons e maus usos da tecnologia, mas observa que ela é neutra e depende de como ela é usada.

- ChatGPT é um chatbot gratuito que pode responder perguntas com eloquência e gerar texto sobre uma variedade de temas
- ChatGPT é baseado no modelo GPT-3 AI, que gera texto baseado em padrões que aprendeu com grandes quantidades de texto na internet
- O ChatGPT se destaca porque pode responder a perguntas naturalmente formuladas e responder usando uma nova variante do GPT-3 chamada GPT-3.5
- A capacidade do ChatGPT de responder a uma ampla gama de perguntas deu ao modelo AI uma nova interface que é acessível a quase todos
- ChatGPT tornou-se popular em parte devido à sua livre disponibilidade e ao potencial de erros humorísticos
- **ChatGPT ainda é propenso a erros e preconceitos, tais como fabricar fatos ou regurgitar declarações de ódio**
- O uso de ChatGPT em colas ou engodos pode ser difícil de detectar, mas **marcas d'água** e ferramentas tecnológicas independentes podem ser usadas para identificar textos gerados artificialmente
- **É importante ter uma combinação de tecnologia e supervisão humana** para evitar que o ChatGPT e outros sistemas de IA causem danos.

---

https://www.wired.com/story/chatgpt-generative-ai-regulation-policy/

# 3 Ways to Tame ChatGPT

Governments around the world are pushing AI regulation that has nothing to say about generative models. That could be dangerous.

>Há três maneiras de domar a inteligência artificial (IA):

Aumentando a transparência nos modelos fundacionais: Pesquisadores e auditores independentes devem avaliar os modelos fundacionais para entender suas vulnerabilidades e preconceitos.

Garantindo transparência no uso de modelos fundacionais: As organizações que implantam modelos fundacionais devem ser transparentes quanto ao seu uso e revelar potenciais danos.

Reforçar a transparência nas aplicações downstream dos modelos fundacionais: As organizações que utilizam sistemas de IA construídos com modelos fundacionais devem ser transparentes quanto ao seu uso e revelar quaisquer danos potenciais.

- Modelos fundacionais de inteligência artificial, incluindo sistemas generativos de IA, tornaram-se a base para muitos sistemas e aplicações baseadas em IA.
- Estes modelos podem ser ajustados por startups de IA para se adequarem a tarefas específicas e são usados em vários campos, incluindo marketing, atendimento ao cliente, desenvolvimento de software e educação.
- Os modelos fundacionais também podem ser usados para espalhar informações errôneas, automatizar spam, escrever malware e plagiar conteúdo, e conter preconceitos e gerar conteúdo preconceituoso.
- **Há uma necessidade de transparência** nos modelos fundacionais, seu uso e as aplicações downstream que dependem deles a fim de resolver os danos potenciais e as questões de responsabilidade que apresentam.
- Os reguladores devem considerar os riscos e os danos potenciais dos modelos fundacionais ao criar a regulamentação da IA e exigir transparência de ponta a ponta na cadeia de fornecimento de IA.
- Os desenvolvedores e usuários de modelos fundacionais também devem considerar as implicações éticas e os impactos potenciais de seu uso.
